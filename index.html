
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head >
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="https://latex.now.sh/style.css">
<title>李润 (Run Li)</title>
</head>
<body>
    <div class="rSection" style="text-align:center">
        <h3 style="text-align:left">Information</h3>
        <hr>
        <strong>Run Li</strong> <br/>
        1037 Luoyu Road Wuhan, China 430074<br/>
       (+86)181 6074 2624<br/>
root999@hust.edu.cn / root999@aliyun.com
    </div>
    <div class="rSection">
        <h3><p><span>Education</span></p></h3>
        <hr>
        <p><span><strong>Huazhong University of Science and
        Technology</strong></span><br />
        M.S. in Software Engineering<br />
        GPA: 3.79/4.00<br />
        Rank: 4/145</p>
        <p><span><strong>NanChang University</strong></span><br />
        B.S. in Software Engineering<br />
        TA in Data Structure &amp; Algorithm</p>
        </div>
        <div class="rSection">
        <h3><p><span>Research Experience</span></p></h3>
        <hr>
        <span><h4>Contrastive Learning and Multi-grained Interactivity of
        Cross Domain Few Shot FAQ</h4></span>
        <em style="float:left"><strong>Alibaba DAMO Academy</strong></em> 
        <i style = "float: right;">Jun 2021 - Sep 2021</i><br/>
        <span><strong>Situation</strong></span>:
        <p>    In the intelligent customer service dialogue system, FAQ is the core
        business scenario. With the success of ToC’s customer service robot,
        AliXiaomi has gradually transformed into a customer service robot
        platform that provides SaaS/PaaS to offer services to various companies
        on Alibaba Cloud. However, B-end client data is quite limited and of low
        quality in the case of ToB. Thus, the quality of FAQ needs to be
        improved. <br/>
        <span><strong>Task</strong></span>:</p>
        <p>    In fact, there are models with good performance in other source
        domains, and it is hoped that the model can be better represented in the
        target domain by introducing mature models in other source domains to
        assist the model learning in the target domain with few shot. The key
        part lies in the utilization of information within and between domains
        to mine the differences and connections between samples.<br/>
        <span><strong>Action</strong></span>:</p>
        <p>    1. <strong>Multi-grained Interactive Learning</strong>: Few shot
        learning aims at the model learning better representation ability
        through a small number of samples. It takes samples by N-way-K-shot
        method to form episodes (corresponding to the conception of batch) for
        training.</p>
        <p>    2. <strong>Contrastive Learning</strong>: In a sampled episode, the
        SimCSE method is used to modify random mask strategy of query, and
        query’s nearest neighbor T is augmented, which is expressed in the
        mature embedding of multi-source domain and the target domain to be
        learned. Contrastive learning is reflected in that the expression
        similarity of different domains of the same query should be greater than
        that of the mature domain of the same query and the nearest neighbor t
        of query in the target domain, which enhances the cohesive expression
        ability of the target domain. Similarly, for the sampled episode, the
        expression similarity between query and nearest neighbor t in the mature
        domain should be greater than that between query in the mature source
        domain and nearest neighbor t in the target domain, which enhances the
        ability to distinguish between the target domain and the mature source
        domain.</p>
        <p><span><strong>Result</strong></span>:</p>
        <p>    With the help of store-Xiaomi in the e-commerce field and government
        affairs Xiaomi in the government service field, the B-end data of Cloud
        Xiaomi improved by about 2% compared with MLMAN method and improved by
        about 8% compared with Transfer Learning. A paper titled “Contrastive
        Learning and Multi-grained Interactivity of Cross Domain Few Shot FAQ”
        is also accomplished.</p><hr>
        <p><span><strong>Short Term Load Forecasting for Power System based on
        Graph Hash Sampling Attention and Contrastive Learning</strong></span>
        <em style="float: right;">May 2022 - present</em><br />
        <span><strong>Situation</strong></span>:</p>
        <p>In order to maintain the highly efficient operation and increase the
        stability of power supply for the entire power grid, power load
        forecasting is a major topic. It can provide convenience for the
        operation planning, income prediction, electricity price design and
        energy transactions of the power system. Short term load forecasting (a
        few minutes or hours in advance) is mainly used to assist real-time
        energy scheduling, which is of great research value to modern power
        systems with uncertainties at the power generation end and power
        consumption end represented by new energy. However, accurate short-term
        load forecasting is challenging.</p> <span><strong>Task</strong></span>:
        <p>The power network is modelled as a graph consisting of nodes and
        edges, which is a non-Euclidean geometry. And it means that the deep
        learning method of graph neural network can be applied in the power
        system network. In particular, for the specific time t, load forecasting
        of a specific node can be considered as a time series prediction
        problem. It aims at predicting the load of the nodes at time t using the
        state set of the previous time t-1 and the input of the current time t.
        This paper uses graph attention and contrastive learning to model the
        space-time graph of power grid.</p>
        <p><span><strong>Action</strong></span>:</p>
        <p>1. <strong>Graph Hash Sampling Attention</strong>: Self attention has
        better long-term sequence correlation modeling ability. However
        attention mechanism take a lot of resources to calculate dot product
        similarity, specially in spatial temporal graph. In this paper, we refer
        the SDIM method use SimHash to approximate attention mechanism. SimHash
        has been proved that has superior modeling performance in long term user
        behavior sequences,and it cost a little of resources.In the
        spatial-temporal graph, because the graph is unstructured data and its
        internal topology is complex, the capacity of the graph attention
        mechanism is limited not to achieve the expected results, so the SimHash
        structure is used to approximate the correlation of the spatial-temporal
        graph, which strengthens the graph representation capability for
        modeling the connection and difference between the power network system
        data exhibited over a long time and wide space.</p>
        <p>2. <strong>Spatial Temporal Graph Contrastive Learning</strong>: In
        deep learning research , contrastive learning is a commonly used
        method of metric learning. This method can strengthen the representation
        ability of the model, the aim of which is to make the relevant features
        closer in space and the unrelated features farther so as to make the
        model more informative (closer to the maximum entropy). In this paper,
        we design the spatial-temporal contrastive learning of graph nodes.
        Temporal contrastive learning can be described as follows: the
        similarity between a specific node and its adjacent node N at time t
        should be greater than that at other time instant. The spatial
        contrastive learning can be described as follows: the similarity of a
        specific node at time T and at non-T time instant should be greater than
        the similarity between and itself at time T and its neighbor at non-T
        time. Through the above description, we can strengthen the node
        representation ability of the model and make the prediction more
        accurate.</p>
        <p><span><strong>Result</strong></span>:</p>
        <p>Compared with the short term load forecasting for power system using
        SOTA method in 2021(Ada-GWN), we find that the MAE value is reduced
        about 0.13 and the MAPE value is reduced about 1.8%. Currently, we are
        adjusting the system parameters and designing further ablation
        experiments.</p>
        </div>
        <div class="rSection">
        <h3><p><span>HONORS &amp; AWARDS</span></p></h3>
        <hr>
        <strong >Excellent Graduate Student of Huazhong University of
        Science and Technology</strong> <em style="float: right;">2022</em><br />
        <span style="float: left;"><strong>National Scholarship</strong></span> <em style="float: right;">2021</em><br />
        <strong>First-class Academic Scholarship of Huazhong University of
        Science and Technology</strong> 
        <em style="float: right;">2019, 2020, 2021</em><br />
        <span style="float: left;"><strong>Merit Postgraduate Student</strong></span> <em style="float: right;">2020,
        2021</em><br />
        <span ><strong>First-class ’Zhixing’ Scholarship of Huazhong University
        of Science and Technology</strong></span><em style="float: right;">2020</em><br />
        <span style="float: left;"><strong>ShenZhen Stock Exchange Scholarship</strong></span>
        <em style="float: right;">2020</em><br />
        <span><strong>The ‘Zhihui Cup’ University Geek Challenge by SPDB &amp;
        Baidu</strong></span><br />
        <em style="float: left;">National Second Award</em> <em style="float: right;">2020</em><br />
        <span style="float: left;"><strong>The Tianchi-Digital China Intelligent Ocean Construction
        algorithm Competition</strong></span><br />
        <em>National Rank: 16/3275</em> <em style="float: right;">2020</em><br />
        <span ><strong>The First National College Students’ Artificial
        Intelligence Innovation Competition</strong> </span><br />
        <em style="float: left;">National Winning Award</em> <em style="float: right;">2018</em><br />
        <span><strong>The Sixth China Software Cup College Students Software
        Design Competition Undergraduate Group</strong> </span><br />
        <em style="float: left;">National Third Award</em> <em style="float: right;">2017</em><br />
        <span><strong>The 2017th ‘Huameng’ National Open Source Software
        Creative Competition for College Students</strong></span><br />
        <em style="float: left;">National First Award</em> <em style="float: right;">2017</em><br />
        <span><strong>The 8th ’Lanqiao Cup’ Jiangxi Division C/C++ Programming
        Group A(Provincial Second Award)</strong></span><br />
        <em style="float: left;">Provincial Second Award</em><em style="float: right;">2017</em><br />
        <span><strong>The 3rd Jiangxi Internet+ College Students Innovation and
        Entrepreneurship Competition</strong></span><br />
        <em style="float: left;">Provincial Bronze Award</em> <em style="float: right;">2017</em><br />
        <span><strong>Special-class Scholarship of Nanchang
        University</strong></span><em style="float: right;">2017</em></p>
        </div>
        <div class="rSection">
        <h3><p><span>Internship Experience</span></p></h3>
        <hr>
         <strong style="float: left;">Alibaba DAMO Academy</strong> <em style="float: right;">Jun 2021 - Sep
        2021</em><br />
        <p>1. Served as a natural language processing algorithm engineer,
        responsible for the TOB’s cloud-Xiaomi few shot dialogue task.</p>
        <p>2. A cross domain learning framework with few shot  based on
          contrastive learning is proposed. This framework can assist in learning
          the target domain in the case of multiple source domains. By further
          deepening the sampling in few shot learning, the expression
          similarity of different domains of the same query should be greater than
          that of mature source domain expression and the query’s nearest neighbor t(generated by random mask with query) in
          the target domain. Similarly, for the sampled episode, the expression
          similarity between query and nearest neighbor t in the mature source domain
          should be greater than that between query in the mature domain and
          nearest neighbor t in the target domain. In summary, the framework
          improves the representation ability of the target domain in the case of
          cold start and few samples. In real business, the time cost of cloud
          Xiaomi B-end customer access is reduced from two weeks to three
          days.<br />
        <strong style="float: left;">Tencent Lightspeed &amp; Quantum Studios</strong> <em style="float: right;">Apr 2021 -
        Jun 2021</em></p><br />
        <p>1. Served as a natural language processing algorithm engineer,
        responsible for the multi style user nickname generation tasks of
        PUBG.</p>
        <p>2. A multi style nickname generation model based on GPT pre-training
        model is proposed and efficiently implemented. Compared with the style
        transformer, a multi style migration model based on cycleGAN and
        STARGAN, and the disentanglement replacement method commonly used in
        speech style migration. The model decouples style tasks and nickname
        tasks. When the model converges, it can generate a total number of
        nicknames with a specified style of about 800million. When
        the model converges, it can generate a total of about 800 million
        nicknames of the specified styles.</p>
        </div>
</body>
</html>
